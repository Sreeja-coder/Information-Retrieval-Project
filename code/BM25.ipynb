{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "corpus = [\n",
    "    \"Hello there good man!\",\n",
    "    \"It is quite windy in London\",\n",
    "    \"How is the weather today?\"\n",
    "]\n",
    "\n",
    "tokenized_corpus = [doc.split(\" \") for doc in corpus]\n",
    "\n",
    "bm25 = BM25Okapi(tokenized_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Hello', 'there', 'good', 'man!'],\n",
       " ['It', 'is', 'quite', 'windy', 'in', 'London'],\n",
       " ['How', 'is', 'the', 'weather', 'today?']]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0        asin                                              query  \\\n",
      "0           0  B00KMB7OK6  ['product', 'description', 'nset', 'music', 'f...   \n",
      "1           1  B00KMRGF28  ['inspiron', '15', 'economical', 'member', 'fa...   \n",
      "2           2  B00KMRGF3M  ['increase', 'storage', 'possibility', 'powerf...   \n",
      "3           3  B00KNM763E  ['home', 'belkin', 'netcam', 'hd', 'deliver', ...   \n",
      "4           4  B00KO6LA8Q  ['compact', 'video', 'audio', 'recorder', 'siz...   \n",
      "\n",
      "                                              cosine  \\\n",
      "0  ['Metric system: Does anybody know if this dev...   \n",
      "1  ['this keyboard work with OSX 10.9 Mavericks?'...   \n",
      "2  ['Will it increase volume for senior who needs...   \n",
      "3  ['Is it just for taking Videos?', 'wi fi only?...   \n",
      "4  ['Is it just for taking Videos?', 'Does this c...   \n",
      "\n",
      "                                                bm25  \n",
      "0  ['Can i connect this to a DLink DIR-615 Wirele...  \n",
      "1  ['Does this keyboard have keys that allow you ...  \n",
      "2  ['will this be powerful enough/compatable for/...  \n",
      "3  ['is it good for video hd streaming', 'Playing...  \n",
      "4  ['Video mode: Has anyone tried the video mode?...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "\n",
    "## *******\" gen and og\"******** ##\n",
    "\n",
    "def eval_gen_og(gen,og):\n",
    "    score = 0\n",
    "    for i in gen:\n",
    "        best = 0\n",
    "        w1 = wn.synsets(i)\n",
    "        if (len(w1) > 0):\n",
    "            for j in og:\n",
    "                w2 = wn.synsets(j)\n",
    "                if len(w2) < 1:\n",
    "                    continue\n",
    "                temp = w1[0].path_similarity(w2[0])\n",
    "                if temp != None and temp > best:\n",
    "                    best = temp\n",
    "        else:\n",
    "            if i in og:\n",
    "                best = 1\n",
    "        #     print(best)\n",
    "        score = score + best\n",
    "\n",
    "    return score / len(gen)\n",
    "\n",
    "\n",
    "\n",
    "## ************\"og and query \"**************** ##\n",
    "def eval_og_query(og,query):\n",
    "    score = 0\n",
    "    for i in og:\n",
    "        best = 0\n",
    "        w1 = wn.synsets(i)\n",
    "        if(len(w1)>0):\n",
    "            for j in query:\n",
    "                w2 = wn.synsets(j)\n",
    "                if len(w2)<1:\n",
    "                    continue\n",
    "                temp = w1[0].path_similarity(w2[0])\n",
    "                if temp!= None and temp > best:\n",
    "                    best = temp\n",
    "        else:\n",
    "            if i in query:\n",
    "                best = 1\n",
    "    #     print(best)\n",
    "        score = score + best\n",
    "    return score/len(og)\n",
    "\n",
    "### ****** \"gen and query \" ***** ####\n",
    "def eval_gen_query(gen,query):\n",
    "    score = 0\n",
    "    for i in gen:\n",
    "        best = 0\n",
    "        w1 = wn.synsets(i)\n",
    "        if (len(w1) > 0):\n",
    "            for j in query:\n",
    "                w2 = wn.synsets(j)\n",
    "                if len(w2) < 1:\n",
    "                    continue\n",
    "                temp = w1[0].path_similarity(w2[0])\n",
    "                if temp != None and temp > best:\n",
    "                    best = temp\n",
    "        else:\n",
    "            if i in query:\n",
    "                best = 1\n",
    "        #     print(best)\n",
    "        score = score + best\n",
    "\n",
    "    return score / len(gen)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "    stop = stopwords.words('english')\n",
    "    df = pd.read_csv('input_for_eval.csv')\n",
    "    print(df.head())\n",
    "    df3_main = pd.read_csv('electronics1.csv', encoding='utf-8')\n",
    "    ultimate_score  = []\n",
    "    df3_main = df3_main[-200:]\n",
    "    for i in df.index:\n",
    "        asin = df.asin[i]\n",
    "        # print(\"asin\",asin)\n",
    "        query = df['query'][i]\n",
    "        # print(\"query\",query)\n",
    "        gen_questions = df.cosine[i]\n",
    "        gen_questions2 = df.bm25[i]\n",
    "        x = df3_main.loc[df3_main['asin'] == str(asin)]\n",
    "        og_questions = x['question'].tolist()\n",
    "\n",
    "        og = []\n",
    "        gen = []\n",
    "        gen2=[]\n",
    "        \n",
    "        for i in og_questions:\n",
    "            text = tokenizer.tokenize(i)\n",
    "            og.extend(text)\n",
    "        for i in gen_questions:\n",
    "            text = tokenizer.tokenize(i)\n",
    "            gen.extend(text)\n",
    "        for i in gen_questions2:\n",
    "            text = tokenizer.tokenize(i)\n",
    "            gen2.extend(text)\n",
    "        og = [x.lower() for x in og]\n",
    "        gen = [x.lower() for x in gen]\n",
    "        gen2 = [x.lower() for x in gen2]\n",
    "  \n",
    "        og = list(set(og))\n",
    "        gen = list(set(gen))\n",
    "        gen2 = list(set(gen2))\n",
    "        og = [word.strip('; : ! * - \\\\ · . ® \\® //') for word in og if word not in (stop)]\n",
    "        gen = [word.strip('; : ! * - \\\\ · . ® \\® //') for word in gen if word not in (stop)]\n",
    "        gen2 = [word.strip('; : ! * - \\\\ · . ® \\® //') for word in gen2 if word not in (stop)]\n",
    "        combined = gen.copy()\n",
    "        combined.extend(gen2)\n",
    "        ultimate_score.append([eval_gen_og(gen,og),eval_gen_og(gen2,og),eval_gen_query(gen,query),eval_gen_query(gen2,query),eval_og_query(og,query)])\n",
    "#         ultimate_score_bm25.append([eval_gen_og(gen,og),eval_gen_query(gen,query),eval_og_query(og,query)])\n",
    "    output_eval = pd.DataFrame(ultimate_score, columns=['comparison_cosine','comparison_bm25', 'model_cosine','model_bm25','original'])\n",
    "    output_eval.to_csv('eval_output_cosine_bm25.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
