{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started cleaning data\n",
      "23931\n",
      "['Sony Hi-8mm Handycam Vision camcorder 330X digital zoom, Nightshot(TM) Infrared 0 lux system, Special Effects, 2.5\" SwivelScreen color LCD and 16:9 recording mode, Laserlink connection. Image Stabilization, remote, built in video light.']\n",
      "[\"Even though the market seems to have an insatiable appetite for premium high definition large screen TVs, there's also significant demand for a premium quality smaller sized high definition TV. Like larger sized '07 XBR models, this model includes key XBR picture quality features such as Motionflow 120Hz for smoother motion and exceptional resolution in fast moving scenes 10-bit panel and processing with 64 times gradation expression over current 8-bit panels and Live Color Creation featuring the WCG-CCFL backlight for an awesome range of vivid colors. Additionally, the 32XBR4 features our BRAVIA Engine EX to reduce digital artifacts and improve overall picture clarity and color performance. Other new features such as DMeX expansion capability, the XMB on-screen interface and BRAVIA Theatre Sync one-touch command add even more value to the picture performance. Ample connections include two HD component inputs, HDMI inputs with 1080/60p and 1080/24p capability and more provide the flexibility to get you connected to just about any HD source. It's a 32? class television AND it's a BRAVIA XBR HDTV too!\", 'Amazon.com Product Description <style type=\"text/css\"> .caption { font-family: Verdana, Helvetica neue, Arial, serif; font-size: 10px; font-weight: bold; font-style: italic; } ul.indent { list-style: inside disc; text-indent: -15px; } </style> The Sony BRAVIA XBR KDL-32XBR4 32-inch 720 LCD Flat Panel HDTV continues Sony\\'s tradition of making outstanding televisions. The display features a 32-inch screen that is perfect for a smaller room. Sony does not hold back with any technologies, and the XBR series is its flagship line--so with the XBR, you know you\\'ll get the best quality home theater experience available.', '', \"Sony complements the high resolution with the latest technology in color reproduction. The KDL-32XBR is a 10-bit display with 10-bit processing. Most panels are only 8-bit. The added bit depth here means a larger color palette for more faithful color reproduction and smoother transitions from one color to the next. Additionally, the display features a special WCG-CCFL backlight that, combined with Sony's Live Color Creation system, achieves more natural and vibrant color.\", \"The KDL-32XBR4 features Sony's Motionflow technology, which automatically adjusts for and applies the proper processing for optimal motion reproduction depending on the video input. This includes support for 24 frames per second (24p) video, which displays video content at the 24-frames-per-second rate at which it was originally filmed or recorded. With 24p, you get the most faithful possible reproduction of the original.\", \"<b>A Wide Variety of Inputs</b><br /> This Sony television's wide variety of inputs ensures compatibility with your other home theater components. There are three HDMI connections for Blu-Ray, HD DVD, and other technologies requiring the high bandwidth, and two component video inputs, three composite video inputs, one S-Video input, one PC Audio and Video input, two RF connection inputs, and five analog audio inputs. Even with a collection of legacy components, you shouldn't have a problem connecting to the KDL-32XBR4.\", \"<b>Stunning Looks</b><br /> The KDL-32XBR4 not only displays stunning video but is itself a head-turner. It features Sony's unique floating glass frame along with a black bezel that can be interchanged with optional color bezels to match the display to your decor.\", \"<b>Outstanding Ergonomics and Simplicity of Control</b><br /> Sony's Xross Media Bar interface is an award-winning, intuitive on-screen display that makes setup a breeze, with menus and controls logically laid out for quick access. The KDL-32XBR4 also features Theatre Sync technology, based on the HDMI-CEC standard, which means you can easily connect to and control compatible devices. For example, when the KDL-32XBR4 is connected to a compatible DVD player, you can turn on both the DVD player and the television and start playing a DVD with a single push of a button on the remote. When you're done, another push of a button powers everything down. With Theatre Sync, you can spend time enjoying the movie rather than waste time setting everything up.\", \"<b>Cutting Edge Sound</b><br /> Using a set of Sony algorithms, the KDL-32XBR4 is capable of generating realistic surround sound from just the two speakers in the TV. With Sony's S-Force Front Surround technology, you can have surround sound no matter the shape or size of your room.\", 'The KDL-32XBR4 is backed by a 1-year limited warranty for parts and labor.', '<br clear=\"all\" />', '']\n",
      "3005\n",
      "['Enjoy entertainment anywhere on this LG portable DVD player; audio/video player features 8-inch swivel screen; music/movie player has convenient touch panel controls; USB media host; up to five hours battery life; ready for road trips with the supplied power outlet charger and automotive charger; A/V input + output; multi-format disc playback: DVD Video/ DVD-R/DVD-RW/Audio CD/CD-R/CD-RW; convenient swivel and flip LCD screen provides a crystal clear picture; high fidelity audio output from stereo speakers or twin earphone jacks; Video DAC: 4 DAC 12-bit; disc playback capability: MP3 audio, DVD-R, DVD-RW, DVD+R, DVD+RW, WMA audio, JPEG photo, Audio CD, DVD (NTSC/PAL), MP3 ID3 TAG, DVD+R double layer, Progressive JPEG.']\n",
      "3006\n",
      "completed descriptions\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-d06a0a06696a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'description'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m45\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m \u001b[0mcleaned_words\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcleaned_questions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mremove_stopwords\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;31m# tokenized_lists_Q = tokenize_description()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-d06a0a06696a>\u001b[0m in \u001b[0;36mremove_stopwords\u001b[1;34m()\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[0mnew_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword_tokenize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcheck_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[1;31m#         new_words = line.split()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mnew_word_questions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkrovetz_stem_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_words\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'completed questions'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnew_word_final\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_word_questions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-1-d06a0a06696a>\u001b[0m in \u001b[0;36mkrovetz_stem_word\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mkrovetz_stem_word\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[0mks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkrovetz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPyKrovetzStemmer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m     \u001b[0mstemmed_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mword\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import nltk\n",
    "import csv\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import krovetz\n",
    "import numpy as np\n",
    "from nltk.corpus import wordnet \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from html import unescape\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "#\n",
    "\n",
    "print(\"started cleaning data\")\n",
    "\n",
    "\n",
    "\n",
    "def remove_stopwords():\n",
    "    stop = stopwords.words('english')\n",
    "    pattern=r'(?i)\\b((?:[a-z][\\w-]+:(?:/{1,3}|[a-z0-9%])|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:\\'\".,<>?«»“”‘’]))';\n",
    "    ks = krovetz.PyKrovetzStemmer()\n",
    "    new_word_final = []\n",
    "    for i in range(3005,3007):\n",
    "        line = df2['description'].iloc[i]\n",
    "        print(line)\n",
    "        line = line.strip('\\[ \\]')\n",
    "        match = re.findall(pattern, line)\n",
    "        for m in match:\n",
    "            url = m[0]\n",
    "            line = line.replace(url, '')\n",
    "        soup = BeautifulSoup(unescape(line), 'lxml')\n",
    "        line = soup.text\n",
    "        line = ' '.join([word.strip('; : ! * - \\\\ · . ® \\® //') for word in line.split() if word not in (stop)])\n",
    "        tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "        text = tokenizer.tokenize(line)\n",
    "        check_pos = lambda pos: pos[:] in ['NN','NNP','CD','NNS', 'JJ','NNPS', 'VBD','POS']\n",
    "        new_words = [x for (x, pos) in nltk.pos_tag(word_tokenize(line)) if check_pos(pos)]\n",
    "#         new_words = line.split()\n",
    "        new_word_final.append(krovetz_stem_word(new_words))\n",
    "        print(i)\n",
    "        \n",
    "\n",
    "    print('completed descriptions')\n",
    "\n",
    "    df['question_no_stopwords'] = df['question'].apply(lambda x: ' '.join([word for word in x.split() if word.lower() not in (stop)]))\n",
    "    #del df['description']\n",
    "    # del df['question']\n",
    "    new_word_questions = []\n",
    "    for i in range(len(df)):\n",
    "        line = df['question'].iloc[i]\n",
    "        line = line.strip('\\[ \\]')\n",
    "        match = re.findall(pattern, line)\n",
    "        for m in match:\n",
    "            line = line.replace(m[0], '')\n",
    "        soup = BeautifulSoup(unescape(line), 'lxml')\n",
    "        line = soup.text\n",
    "        line = ' '.join([word.strip('; : ! * - \\\\ · . ® \\® //') for word in line.split() if word not in (stop)])\n",
    "        tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "        text = tokenizer.tokenize(line)\n",
    "        check_pos = lambda pos: pos[:] in ['NN','NNP','CD','NNS', 'JJ','NNPS', 'VBD','POS']\n",
    "        new_words = [x for (x, pos) in nltk.pos_tag(word_tokenize(line)) if check_pos(pos)]\n",
    "#         new_words = line.split()\n",
    "        new_word_questions.append(krovetz_stem_word(new_words))\n",
    "    print('completed questions')\n",
    "    return new_word_final,new_word_questions\n",
    "#\n",
    "def tokenize_description():\n",
    "# =============================================================================\n",
    "#     tokenized_lists_D = []\n",
    "#     ##  tokenizing description  ###\n",
    "#     for des in df['description_no_stopwords']:\n",
    "#         #     word_tokens = word_tokenize(des)\n",
    "#         tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "#         new_words = tokenizer.tokenize(des)\n",
    "#         tokenized_lists_D.append(new_words)\n",
    "# =============================================================================\n",
    "\n",
    "    ## tokenize questions\n",
    "    tokenized_lists_Q = []\n",
    "    for des in df['question_no_stopwords']:\n",
    "        #     word_tokens = word_tokenize(des)\n",
    "        tokenizer = nltk.RegexpTokenizer(r\"\\w+\")\n",
    "        new_words = tokenizer.tokenize(des)\n",
    "        tokenized_lists_Q.append(new_words)\n",
    "    return tokenized_lists_Q\n",
    "#\n",
    "def krovetz_stem(tokenized_list):\n",
    "    ks = krovetz.PyKrovetzStemmer()\n",
    "    stemmed_list = []\n",
    "    for l in tokenized_list:\n",
    "        new_list = []\n",
    "        for word in l:\n",
    "            newword = \"\"\n",
    "            try:\n",
    "                newword =  ks.stem(word)\n",
    "            except:\n",
    "                newword = word\n",
    "            new_list.append(newword)\n",
    "        stemmed_list.append(new_list)\n",
    "    return stemmed_list\n",
    "\n",
    "def krovetz_stem_word(word):\n",
    "    ks = krovetz.PyKrovetzStemmer()\n",
    "    stemmed_list = []\n",
    "    for i in word:\n",
    "        try:\n",
    "            stemmed_list.append(ks.stem(i))\n",
    "        except:\n",
    "            print(i)\n",
    "            stemmed_list.append(i)\n",
    "    return stemmed_list\n",
    "        \n",
    "\n",
    "\n",
    "##calling functions to clean data:\n",
    "\n",
    "#reading the csv file\n",
    "df=pd.read_csv('electronics.csv',encoding='utf-8')\n",
    "df2 = df.copy()\n",
    "df2 = df2.drop_duplicates(subset = [\"asin\"])\n",
    "df2 = df2.reset_index(drop=True)\n",
    "print(len(df2))\n",
    "df = df.drop(['description'], axis=1)\n",
    "print(df2['description'][45])\n",
    "cleaned_words,cleaned_questions = remove_stopwords()\n",
    "\n",
    "# tokenized_lists_Q = tokenize_description()\n",
    "# print(len(tokenized_lists_Q),\"000\")\n",
    "#\n",
    "# =============================================================================\n",
    "# tokenize_stemmed_stopword_list_D = krovetz_stem(tokenized_lists_D)\n",
    "# =============================================================================\n",
    "# tokenize_stemmed_stopword_list_Q = krovetz_stem(tokenized_lists_Q)\n",
    "# print(len(tokenize_stemmed_stopword_list_Q),\"123\")\n",
    "# print(tokenize_stemmed_stopword_list_D)\n",
    "\n",
    "# df[\"q_tokenized_stemmed_no_stopwords\"]=tokenize_stemmed_stopword_list_Q\n",
    "# =============================================================================\n",
    "# df[\"d_tokenized_stemmed_no_stopwords\"]=tokenize_stemmed_stopword_list_D\n",
    "# =============================================================================\n",
    "#\n",
    "#\n",
    "# print(df[\"q_tokenized_stemmed_no_stopwords\"][45])\n",
    "\n",
    "\n",
    "print(\"ending cleaning data\")\n",
    "print(len(df))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = {}\n",
    "\n",
    "print(\"started tfidf data\")\n",
    "\n",
    "### creating columns of the tf-idf matrix ###\n",
    "\n",
    "def creating_columns():\n",
    "    columns_tfidf = set()\n",
    "    for row in cleaned_words:\n",
    "        for word in row:\n",
    "            columns_tfidf.add(word)\n",
    "    print('----------------------------------------')\n",
    "    print(len(cleaned_words))\n",
    "    print(len(columns_tfidf))\n",
    "    print('=========================================')\n",
    "    return columns_tfidf\n",
    "\n",
    "#calculate document frequency\n",
    "def cal_doc_freq(columns_tfidf):\n",
    "    # DF = {}\n",
    "    for word in columns_tfidf:\n",
    "        for i in range(len(cleaned_questions)):\n",
    "            if (word in cleaned_questions[i]):\n",
    "                try:\n",
    "                    DF[word].add(i)\n",
    "                except:\n",
    "                    DF[word] = {i}\n",
    "    for i in DF:\n",
    "        DF[i] = len(DF[i])\n",
    "    return DF\n",
    "\n",
    "def word_doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c\n",
    "\n",
    "#calculate document frequency for each word\n",
    "def cal_inv_doc_freq(columns_tfidf):\n",
    "    cal_doc_freq(columns_tfidf)\n",
    "    iDF = {}\n",
    "    for i in DF:\n",
    "        iDF[i] = np.log(len(cleaned_questions) + 1 / (DF[i] + 1))\n",
    "    return iDF\n",
    "\n",
    "def term_freq():\n",
    "    term_freq_dict = dict()\n",
    "    print(\"inside term_freq\",len(cleaned_questions))\n",
    "    for index in range(len(cleaned_questions)):\n",
    "        for word in columns_tfidf:\n",
    "            if word in cleaned_questions[index]:\n",
    "                term_freq_dict.setdefault(index, []).append((word, cleaned_questions[index].count(word)))\n",
    "    print(\"inside term_freq\",len(term_freq_dict))\n",
    "    return term_freq_dict\n",
    "\n",
    "\n",
    "def cal_tf_idf():\n",
    "    tf_idf = dict()\n",
    "    for key, value in term_freq_dict.items():\n",
    "        for val in value:\n",
    "            tf_idf.setdefault(key, []).append((val[0], iDF[val[0]] * val[1]))\n",
    "    return tf_idf\n",
    "\n",
    "# =============================================================================\n",
    "# def definition(word_list):\n",
    "#     temp = set()\n",
    "#     for i in word_list:\n",
    "#         syns = wordnet.synsets(i)\n",
    "#         if(len(syns) == 0):\n",
    "#             continue\n",
    "#         text = syns[0].definition()\n",
    "# # =============================================================================\n",
    "# #         print(nltk.pos_tag(text))\n",
    "# # =============================================================================\n",
    "#         check_pos = lambda pos: pos[:2] in ['NN','NNP','CD','NNS', 'JJ','NNPS']\n",
    "#         nouns = [x for (x, pos) in nltk.pos_tag(text) if check_pos(pos)]\n",
    "#         temp.update(nouns)\n",
    "#     temp.update(word_list)\n",
    "#     return temp\n",
    "# =============================================================================\n",
    "\n",
    "\n",
    "####calling the functions\n",
    "\n",
    "columns_tfidf = creating_columns()\n",
    "# =============================================================================\n",
    "# columns_tfidf = definition(columns_tfidf)\n",
    "# =============================================================================\n",
    "# print(len(columns_tfidf))\n",
    "# print(len(tokenize_stemmed_stopword_list_Q))\n",
    "iDF = cal_inv_doc_freq(columns_tfidf)\n",
    "term_freq_dict = term_freq()\n",
    "tf_idf = cal_tf_idf()\n",
    "print(len(tf_idf))\n",
    "\n",
    "\n",
    "print(\"ending tfidf data\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import Counter\n",
    "print(\"started cosine  distance\")\n",
    "## cal the tf-idf matrix :\n",
    "\n",
    "sorted(columns_tfidf)\n",
    "print(len(columns_tfidf))\n",
    "columns = list(columns_tfidf)\n",
    "\n",
    "\n",
    "D = np.zeros((len(cleaned_questions), len(columns_tfidf)))\n",
    "for key,values in tf_idf.items():\n",
    "    # print(key)\n",
    "    # print(values)\n",
    "    # print(\"i\",i)\n",
    "    for v in values:\n",
    "        # print(v)\n",
    "        try:\n",
    "            # print(\"inside try\")\n",
    "            ind = columns.index(v[0])\n",
    "            # print(v[0])\n",
    "            # print(ind)\n",
    "            D[key][ind] = v[1]\n",
    "            # print(D[key][ind])\n",
    "        except:\n",
    "            # print(\"in except\")\n",
    "            pass\n",
    "\n",
    "\n",
    "# print(columns.index(\"try\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(map(max, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_vector(tokens):\n",
    "    Q = np.zeros((len(columns)))\n",
    "\n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "\n",
    "    query_weights = {}\n",
    "\n",
    "    for token in np.unique(tokens):\n",
    "\n",
    "        tf = counter[token] / words_count\n",
    "        df = word_doc_freq(token)\n",
    "        idf = math.log((len(cleaned_questions) + 1) / (df + 1))\n",
    "\n",
    "        try:\n",
    "            ind = columns.index(token)\n",
    "            Q[ind] = tf * idf\n",
    "        except:\n",
    "            pass\n",
    "    return Q\n",
    "\n",
    "\n",
    "\n",
    "def cosine_sim(a, b):\n",
    "    cos_sim = np.dot(a, b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim\n",
    "#\n",
    "def cosine_similarity(k, query):\n",
    "    print(\"Cosine Similarity\")\n",
    "#     preprocessed_query = preprocess(query)\n",
    "#     tokens = word_tokenize(str(preprocessed_query))\n",
    "\n",
    "    print(\"\\nQuery:\", query)\n",
    "#     print(\"\")\n",
    "#     print(tokens)\n",
    "\n",
    "    d_cosines = []\n",
    "\n",
    "    query_vector = gen_vector(query)\n",
    "    \n",
    "    print(\"len\",len(query_vector))\n",
    "    for d in D:\n",
    "        d_cosines.append(cosine_sim(query_vector, d))\n",
    "\n",
    "#     print(d_cosines)\n",
    "    out = np.array(d_cosines).argsort()[:k][::-1]\n",
    "\n",
    "    print(\"\")\n",
    "\n",
    "    print(out)\n",
    "    for o in out:\n",
    "        print(df['question'][o])\n",
    "#\n",
    "Query = cleaned_words[0]\n",
    "cosine_similarity(10,Query)\n",
    "print(Query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= gen_vector(Query)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_words[20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
